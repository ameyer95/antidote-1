\section{Real-Valued Features and Categorical Output}

Without loss of generality, suppose our training sets are over elements in
$\mathcal{X} \times \mathcal{Y}$ where
$\mathcal{X} = \mathbb{R}$ and $\mathcal{Y} = \{1, \ldots, k\}$.
A number of details in both the concrete and abstract semantics must be amended.


\paragraph{Clarifying the Concrete Semantics}

When we have categorical output, we no longer return a simple Bernoulli distribution.
In general, we have a probability mass function of the form
\[
    p(i) = \begin{cases}
        c_1 & i = 1 \\
        \ldots \\
        c_k & i = k
    \end{cases}
\]
where each $c_i \in [0, 1]$ and $\sum_{i} c_i = 1$.
We will represent such distributions as a tuple $p = (p_1, \ldots, p_k)$.
Accordingly, $\mathit{summary}(T)$ must return some appropriate element in $[0,1]^k$.
We define it as follows:
\[
    \mathit{summary}(T) \coloneqq
    \text{map} \left(\lambda i \ldotp \frac{\lvert\{(x,y) \in T : y = i\}\rvert}{|T|},
    (1,\ldots,k) \right)
\]
Similarly, $\mathit{impurity}(T)$ must also be updated.
The original choice of Gini Impurity generalizes to the categorical case as follows:
\[
    \mathit{impurity}(T) \coloneqq
    \text{let } (p_1, \ldots, p_k) = \mathit{summary}(T) \text{ in}
    \sum_{i=1}^k p_i (1 - p_i)
\]

For real-valued predicates, we consider functions of the form
$\lambda x \ldotp x \leq \tau$ for some choice of $\tau$.
While there are infinitely many such predicates, a finite set of representatives
will be considered based on the elements of $T$:
specifically, if we sort $T$ by increasing $x$,
then whenever we encounter an adjacent pair $(x_1, x_2)$ with $x_1 < x_2$,
we will include $\tau = \frac{1}{2}(x_1 + x_2)$ as a predicate.
Accordingly, we make a small change to $\mathit{bestsplit}(T)$
to first iterate over the training set to compute the representative predicates,
and then proceed as before, when we assumed that $\Phi$ was finite.


\paragraph{Clarifying the Abstract Semantics}

Once we specify $\mathit{summary}^\#(T^\#)$ for the categorical case
(say, by considering boxes for $(p_1, \ldots p_k)$),
we use our interval arithmetic to handle $\mathit{impurity}^\#(T^\#)$.
In fact, we can do something slightly more precise:
observe that $\sum_{i=1}^k p_i (1 - p_i) = 1 - \sum_{i=1}^k p_i^2$
(the right hand side assumes $\sum_{i=1}^k p_i = 1$).
However, when we have a simple box representing many (infeasible) concrete distributions
(in that their components do not sum to 1),
the interval arithmetic in the latter form has the potential to be more precise;
however, it is not strictly more precise due to some arithmetical quirks,
so we can simply perform both versions and (soundly, more precisely) take their meet.
For example, let $p_1^\# = [0.2, 0.4]$ and $p_2^\# = [0.6, 0.8]$.
Then $(p_1^\# (1 - p_1^\#) + p_2^\# (1 - p_2^\#) = [0.24, 0.64]$,
while $1 - ({p_1^\#}^2 + {p_2^\#}^2) = [0.2, 0.6]$,
and their meet gives us $[0.24, 0.6]$.
\todo{This should/could be done for the binary output case, as well.}

Handling the real-valued features is slightly more involved.
By example, if the $x$ values in $T$ are $\{0, 4, 10, 12\}$, then in the concrete case,
we would have chosen predicates with $\tau \in \{2, 7, 11\}$.
Here, we will symbolically represent large classes of predicates:
each $\varphi^\#$ will look like $\lambda x \ldotp x \leq [\tau_\ell, \tau_u)$
(which involves 3-valued comparison to an interval).
We will pick a finite set of representative, symbolic predicates in a straightforward way
by using the values in $T$ as the actual endpoints of these $\tau^\#$ intervals.;
for $\langle T, n \rangle$ for this $T$ and \emph{any} choice of $n$, we will consider
$\tau^\# \in \{[0, 4), [4, 10), [10, 12)\}$.
In doing so, if any number of elements are missing from $T$, the possible resultant threshold
picked for a representative feature
will still be in one of these possibilities.

The remaining detail is that $\langle T, n \rangle \upharpoonright \varphi^\#$
must also be redefined since our $\varphi^\#$ are effectively predicates in 3-value logic.
We formalize it as follows:
\begin{align*}
    \langle T, n \rangle \upharpoonright \lambda x \ldotp x \leq [a, b)
    \coloneqq&~
    \text{let } T_\text{true} = \{(x,y) \in T : x \leq a\} \text{ and }
    T_\text{maybe} = \{(x,y) \in T : a < x < b\} \text{ in} \\
    &~\langle T_\text{true} \cup T_\text{maybe},
    \min(n + |T_\text{maybe}|, |T_\text{true} \cup T_\text{maybe}| ) \rangle
\end{align*}
The justification for the possible increase in $n$ is that all the original $n$ missing elements
could be gone from $T_\text{true}$,
while the elements in $T_\text{maybe}$ all could possibly be erroneous as well.
\todo{For unbounded disjuncts, we could potentially split into the two different cases, explictly,
if this turns out to be a notable source of imprecision.}
